{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA 潛在語意分析，使用 gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "dictionary = corpora.Dictionary(document.split() for document in open('data/demo_lyrics_seg.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: [u'\\u5feb\\u6a02', u'\\u5de7\\u514b\\u529b', u'\\u7406\\u60f3', u'\\u5496\\u5561', u'\\u98db\\u7fd4']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\xe5\\xb7\\xa7\\xe5\\x85\\x8b\\xe5\\x8a\\x9b', '\\xe4\\xb8\\x96\\xe7\\x95\\x8c', '\\xe9\\xa2\\xa8\\xe6\\x99\\xaf'], ['\\xe6\\x84\\x9b\\xe6\\x83\\x85', '\\xe7\\x94\\x9c\\xe7\\xbe\\x8e', '\\xe7\\x90\\x86\\xe6\\x83\\xb3', '\\xe5\\xb7\\xa7\\xe5\\x85\\x8b\\xe5\\x8a\\x9b', '\\xe5\\xbf\\xab\\xe6\\xa8\\x82', '\\xe6\\xbb\\x8b\\xe5\\x91\\xb3'], ['\\xe4\\xb8\\x96\\xe7\\x95\\x8c', '\\xe6\\x84\\x9b\\xe6\\x83\\x85', '\\xe5\\x92\\x96\\xe5\\x95\\xa1', '\\xe7\\x94\\x9c\\xe7\\xbe\\x8e'], ['\\xe6\\x84\\x9b\\xe6\\x83\\x85', '\\xe9\\xa2\\xa8\\xe6\\x99\\xaf', '\\xe6\\x84\\x9b\\xe6\\x83\\x85', '\\xe5\\x92\\x96\\xe5\\x95\\xa1'], ['\\xe6\\x84\\x9b\\xe6\\x83\\x85', '\\xe6\\xbb\\x8b\\xe5\\x91\\xb3', '\\xe7\\x94\\x9c\\xe7\\xbe\\x8e'], ['\\xe5\\xa4\\xa2\\xe6\\x83\\xb3'], ['\\xe9\\x99\\xbd\\xe5\\x85\\x89', '\\xe5\\xa4\\xa2\\xe6\\x83\\xb3'], ['\\xe9\\x99\\xbd\\xe5\\x85\\x89', '\\xe9\\xa3\\x9b\\xe7\\xbf\\x94', '\\xe5\\xa4\\xa2\\xe6\\x83\\xb3'], ['\\xe9\\x99\\xbd\\xe5\\x85\\x89', '\\xe7\\x90\\x86\\xe6\\x83\\xb3', '\\xe9\\xa3\\x9b\\xe7\\xbf\\x94']]\n"
     ]
    }
   ],
   "source": [
    "texts = [[word for word in document.split()]\n",
    "         for document in open('data/demo_lyrics_seg.txt')]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 0\n",
      "[(u'\\u611b\\u60c5', 0.71487716371695076), (u'\\u751c\\u7f8e', 0.40030631824144625), (u'\\u5496\\u5561', 0.28652980644694653), (u'\\u6ecb\\u5473', 0.27106193453225202), (u'\\u5de7\\u514b\\u529b', 0.20578482989003349), (u'\\u98a8\\u666f', 0.20546545015982653), (u'\\u4e16\\u754c', 0.17742441113126872), (u'\\u7406\\u60f3', 0.17601679042327195), (u'\\u5feb\\u6a02', 0.15760480246795891), (u'\\u967d\\u5149', 0.025863037818709526), (u'\\u98db\\u7fd4', 0.023082088626059), (u'\\u5922\\u60f3', 0.0081152410401324048)]\n",
      "debug 1\n",
      "[(u'\\u967d\\u5149', 0.64890367236816204), (u'\\u5922\\u60f3', 0.51440997789451515), (u'\\u98db\\u7fd4', 0.46806292653010778), (u'\\u7406\\u60f3', 0.26261538395779432), (u'\\u611b\\u60c5', -0.091245447220822076), (u'\\u5496\\u5561', -0.082665317410177144), (u'\\u98a8\\u666f', -0.060709996377469884), (u'\\u5feb\\u6a02', 0.048155049319669338), (u'\\u6ecb\\u5473', 0.042076791584799315), (u'\\u4e16\\u754c', -0.042061470996758651), (u'\\u5de7\\u514b\\u529b', 0.038101974337643611), (u'\\u751c\\u7f8e', 0.01006839557006634)]\n"
     ]
    }
   ],
   "source": [
    "print('debug 0')\n",
    "print(lsi.show_topic(0, topn=20))\n",
    "print('debug 1')\n",
    "print(lsi.show_topic(1, topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"巧克力 世界 風景\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.99999994), (2, 0.99979514), (3, 0.99828625), (4, 0.99670351), (1, 0.96405917), (8, 0.052201528), (7, -0.074385986), (6, -0.080131441), (5, -0.093506016)]\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus], num_features=12)\n",
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.99999636), (0, 0.99984622), (3, 0.99915886), (4, 0.99512786), (1, 0.95925266), (8, 0.034684129), (7, -0.091859251), (6, -0.09759602), (5, -0.1109481)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"愛情\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "index = similarities.MatrixSimilarity(lsi[corpus], num_features=12)\n",
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實戰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_data_file = 'data/lyrics_word_net.dataset'\n",
    "stop_word_file = 'data/stop_words.txt'\n",
    "\n",
    "with open(stop_word_file) as f:\n",
    "    stop_word_content = f.readlines()\n",
    "stop_word_content = [x.strip() for x in stop_word_content]\n",
    "stop_word_content = \" \".join(stop_word_content)\n",
    "\n",
    "dictionary = corpora.Dictionary(document.split() for document in open(input_train_data_file))\n",
    "stoplist = set(stop_word_content.split())\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
    "            if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)\n",
    "dictionary.compactify()\n",
    "\n",
    "texts = [[word for word in document.split() if word not in stoplist]\n",
    "         for document in open(input_train_data_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] >= 1]\n",
    "         for text in texts]\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(206, 0.99755716), (204, 0.95901793), (201, 0.95414102), (184, 0.94575286), (216, 0.94065785)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"沒有 山 不能 跨越 沒有 海 不能 冒險 讓 歷史 記得 這 一天 當我 用心 立下 諾言 沒有 事 不能 改變 沒有 夢 不能 實現 我 站 在 未來 最 前線 抬頭 迎接 每個 考驗 海闊天空 是 我 的 地圖 想 寫下 全新 紀錄 放眼 天下 在 等 我 去 征服 用 熱血 燃燒 黑夜 等待 最 燦爛 的 日出 看 陽光 與 我 賽跑 風雨 和 我 狂飆 我 的 驕傲 自己 打造 每個 夢 永遠 比天 高 一顆 心 為 希望 在 跳躍 讓 世界 為 我 歡呼 大地 為 我 炫耀 我 的 驕傲 你 會 看到 汗 和 淚 痛苦 的 煎熬 在 這 一刻 都 是 我 光榮 的 記號 海闊天空 是 我 的 地圖 想 寫下 全新 紀錄 放眼 天下 在 等 我 去 征服 用 熱血 燃燒 黑夜 等待 最 燦爛 的 日出 看 陽光 與 我 賽跑 風雨 和 我 狂飆 我 的 驕傲 自己 打造 每個 夢 永遠 比天 高 一顆 心 為 希望 在 跳躍 讓 世界 為 我 歡呼 大地 為 我 炫耀 我 的 驕傲 你 會 看到 汗 和 淚 ~ 痛苦 的 煎熬 在 這 一刻 都 是 我 ~ 光榮 的 記號 看 陽光 與 我 賽跑 風雨 和 我 狂飆 我 的 驕傲 自己 打造 每個 夢 ~ 永遠 比天 高 一顆 心 ~ 為 希望 在 跳躍 在 跳躍 ) 讓 世界 為 我 歡呼 大地 為 我 炫耀 我 的 驕傲 你 會 看到 你 會 看到 汗 和 淚 痛苦 的 煎熬 在 這 一刻 都 是 我 光榮 的 記號\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "\n",
    "index = similarities.MatrixSimilarity(lsi[corpus], num_features=100)\n",
    "sims = index[vec_lsi]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "相似歌詞： 沒有 山 不能 跨越 沒有 海 不能 冒險 讓 歷史 記得 這 一天 當我 用心 立下 諾言 沒有 事 不能 改變 沒有 夢 不能 實現 我 站 在 未來 最 前線 抬頭 迎接 每個 考驗 海闊天空 是 我 的 地圖 想 寫 全新 紀錄 放眼 天下 在 等 我 去 征服 用 熱血 燃燒 黑夜 等 最 燦爛 的 日出 看 陽光 與 我 賽跑 風雨 和 我 狂奔 我 的 驕傲 自己 打造 每個 夢 永遠 比天 高 一顆 心 為 希望 在 跳躍 讓 世界 為 我 歡天喜地 大地 為 我 炫耀 我 的 驕傲 你 會 看見 汗水 和 淚水 痛苦 的 煎熬 在 這 一刻 都 是 我 光榮 的 記號 海闊天空 是 我 的 地圖 想 寫 全新 紀錄 放眼 天下 在 等 我 去 征服 用 熱血 燃燒 黑夜 等 最 燦爛 的 日出 看 陽光 與 我 賽跑 風雨 和 我 狂奔 我 的 驕傲 自己 打造 每個 夢 永遠 比天 高 一顆 心 為 希望 在 跳躍 讓 世界 為 我 歡天喜地 大地 為 我 炫耀 我 的 驕傲 你 會 看見 汗水 和 淚水 痛苦 的 煎熬 在 這 一刻 都 是 我 光榮 的 記號 看 陽光 與 我 賽跑 風雨 和 我 狂奔 我 的 驕傲 自己 打造 每個 夢 永遠 比天 高 一顆 心 為 希望 在 跳躍 在 跳躍 讓 世界 為 我 歡天喜地 大地 為 我 炫耀 我 的 驕傲 你 會 看見 你 會 看見 汗水 和 淚水 痛苦 的 煎熬 在 這 一刻 都 是 我 光榮 的 記號\n",
      "\n",
      "相似度： 0.997557\n",
      "試聽連結： http://tw.kkbox.com/song/JnBsJtc06MPXHPBIfPBIf0P4-index.html\n",
      "\n",
      "\n",
      "相似歌詞： 當 我 和 世界 不 一樣 那 就讓 我 不 一樣 執著 對 我 來說 就是 以 剛克剛 我 如果 對 自己 妥協 如果 對 自己 說謊 即使 別人 原諒 我 也 不能 原諒 最美 的 願望 一定 最 瘋狂 我 就是 我 自己 的 神 在 我活 的 地方 我 和 我 最後 的 倔強 握緊 雙手 絕對 不 放 下 一站 是不是 天堂 就算 失望 不能 絕望 我 和 我 驕傲 的 倔強 我 在 風中 大聲 的 唱 這 一次 為 自己 瘋狂 就 這 一次 我 和 我 的 倔強 對 愛我 的 人別 緊張 我 的 固執 很 善良 我 的 手越 骯髒 眼神 越是 發光 你 不在乎 我 的 過往 看見 了 我 的 翅膀 你 說 被 火燒 過 才能 出現 鳳凰 逆流 的 方向 更 適合 飛翔 我 不怕 千萬 人 阻撓 只怕 自己 投降 我 和 我 最後 的 倔強 握緊 雙手 絕對 不 放 下 一站 是不是 天堂 就算 失望 不能 絕望 我 和 我 驕傲 的 倔強 我 在 風中 大聲 的 唱 這 一次 為 自己 瘋狂 就 這 一次 我 和 我 的 倔強 我 和 我 最後 的 倔強 握緊 雙手 絕對 不 放 下 一站 是不是 天堂 就算 失望 不能 絕望 我 和 我 驕傲 的 倔強 我 在 風中 大聲 的 唱 這 一次 為 自己 瘋狂 就 這 一次 我 和 我 的 倔強 就 這 一次 讓 我 大聲 唱 啦 啦 啦 就算 失望 不能 絕望 啦 啦 啦 就 這 一次 我 和 我 的 倔強\n",
      "\n",
      "相似度： 0.959018\n",
      "試聽連結： http://tw.kkbox.com/song/0EJxi-zbwD6Pd1Kch1Kch0H4-index.html\n",
      "\n",
      "\n",
      "相似歌詞： 你 是不是 像 我 在 太陽 下 低頭 流著 汗水 靜靜 辛苦 的 工作 你 是不是 像 我 就算 受 了 冷漠 也 不 放棄 自己 想要 的 生活 你 是不是 像 我 整天 忙 著 追求 追求 一種 你 想不到 的 溫柔 你 是不是 像 我 就算 受 了 冷漠 一次 一次 徘徊 在 十字街頭 因為 我 不在乎 別人 怎麼 說 我 從來 沒有 忘記 我 對 自己 的 承諾 對愛的 執著 我 知道 我 的 未來 不是 夢 我 認真 的 過每 一分鐘 我 的 未來 不是 夢 我 的 心 跟 著 希望 在 動 我 的 未來 不是 夢 我 認真 的 過每 一分鐘 我 的 未來 不是 夢 我 的 心 跟 著 希望 在 動 跟 著 希望 在 動 你 是不是 像 我 整天 忙 著 追求 追求 一種 你 想不到 的 溫柔 你 是不是 像 我 就算 受 了 冷漠 也 不 放棄 自己 想要 的 生活 因為 我 不在乎 別人 怎麼 說 我 從來 沒有 忘記 我 對 自己 的 承諾 對愛的 執著 我 知道 我 的 未來 不是 夢 我 認真 的 過每 一分鐘 我 的 未來 不是 夢 我 的 心 跟 著 希望 在 動 我 的 未來 不是 夢 我 認真 的 過每 一分鐘 我 的 未來 不是 夢 我 的 心 跟 著 希望 在 動 跟 著 希望 在 動\n",
      "\n",
      "相似度： 0.954141\n",
      "試聽連結： http://tw.kkbox.com/song/DCC6zn0SvOlPO2QDe2QDe0H4-index.html\n",
      "\n",
      "\n",
      "相似歌詞： 我 的 心內 感覺 人生 的 沉重 不敢 來 振動 我 不是 好子 嘛 不是 歹人 我 只是 愛眠 夢 我 不願 隨浪 隨風 飄浪 西東 像 船無港 我 不願 做人 奸巧 鑽縫 甘願 來作 憨人 我 不是 頭腦 空蕩 我 不是 一隻 米蟲 人 啊 人 一 世人 要安 怎麼 歡天喜地 過 春夏秋冬 我 有 我 的 路 有 我 的 夢 夢中 的 那個 世界 甘講 伊是 一場空 我 走過 的 路 只有 希望 希望 你 我 講過 的話 放在 心肝 內 總有一天 看見 滿天 全部 金條 要 煞 無半項 環境 來 戲弄 背景 無夠強 天才 無夠 弄 逐項 是 攏 輸人 只得 看透 這 虛華 不怕 路 歹行 不怕 大雨淋 心上 一字敢 面對 我 的 夢 甘願 來作 憨人 我 不是 頭腦 空蕩 我 不是 一隻 米蟲 人 啊 人 一 世人 要安 怎麼 歡天喜地 過 春夏秋冬 我 有 我 的 路 有 我 的 夢 夢中 的 那個 世界 甘講 伊是 一場空 我 走過 的 路 只有 希望 希望 你 我 講過 的話 放在 心肝 內 總有一天 我 有 我 的 路 有 我 的 夢 夢中 的 那個 世界 甘講 伊是 一場空 我 走過 的 路 只有 希望 希望 你 我 講過 的話 放在 心肝 內 總有一天 總有一天\n",
      "\n",
      "相似度： 0.945753\n",
      "試聽連結： http://tw.kkbox.com/song/jA8Vro5MD9mSs12.Y12.Y0H4-index.html\n",
      "\n",
      "\n",
      "相似歌詞： 經過 了 漫長 的 等 夢想 是 夢想 我 還是 一個 我 那 時間 忘記 挽留 最美 時候 不經意 匆匆 的 放過 曾經 想 擁抱 的 彩虹 盛開 的 花朵 那 純純 的 笑容 突然 有 風吹 過 那 一轉眼 只 剩 我 我 不 懂 人世間 的 那些 愁 他 為 什麼 要 纏 著 我 到底 這會 是 誰 的 錯 還是 我 不 放手 喔 人世間 的 那些 愁 這 世界 給我 的 幽默 這 是不是 要 告訴 我 潮起 終於 潮落 總要 有人 來 陪伴 我 嚥下 苦果 喔 再 嚐 一些 美夢 要 等 你 先 開口 那 冬天 才 會 走 有些 人 經過 我 身邊 住 在 我 腦中 在 我心 裡 鑽洞 有些 人 變成 相片 堆 在 角落 灰塵 像 雪 一般 冰 時間 如果 可以 倒流 我 想 我 還是 會 卯起來 蹉跎 反正 就 這樣 吧 我 知道 我 努力 過 我 想 遠 遠 的 以後 會 不會 有人 知道 我 在 這個 孤單 的 星球 曾經 這樣 的 活過 喔 遠 遠 的 以後 天長 和 地久 的 盡頭 應該 沒有 人能 搶走 我 永遠 的 感動 總要 有 一首 我 的 歌 大聲 唱過 喔 再 看 天地 遼闊 活著 不多不少 幸福 剛好 夠用 活著 其實 很 好 再 吃 一顆 蘋果\n",
      "\n",
      "相似度： 0.940658\n",
      "試聽連結： http://tw.kkbox.com/song/Lp-3mrZtv.aXr3g3T3g3T0H4-index.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics = [];\n",
    "fp = open(\"data/lyrics_word_net.dataset\")\n",
    "for i, line in enumerate(fp):\n",
    "    lyrics.append(line)\n",
    "fp.close()\n",
    "\n",
    "url = [];\n",
    "fp = open(\"data/lyrics_url.dataset\")\n",
    "for i, line in enumerate(fp):\n",
    "    url.append(line)\n",
    "fp.close()\n",
    "\n",
    "for lyric in sims[:5]:\n",
    "    print \"\\n相似歌詞：\",  lyrics[lyric[0]]\n",
    "    print \"相似度：\",  lyric[1]\n",
    "    print \"試聽連結：\",  url[lyric[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
